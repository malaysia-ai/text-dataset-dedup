{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f25a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/Malaysian-SFT/resolve/main/data/chatgpt4_malaysian_general_qa-00000-of-00001.parquet\n",
    "# !wget https://huggingface.co/datasets/mesolitica/Malaysian-SFT/resolve/main/data/malaysian_ultrachat-00000-of-00001.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30bc3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/chatgpt-malay-instructions/resolve/main/synthetic-alpaca_data_cleaned.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d710cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/chatgpt-malay-instructions/resolve/main/synthetic-code-instructions.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c842a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/mixtral-malaysian-general-qa/resolve/main/mixtral-conversation-stupid.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/mixtral-malaysian-general-qa/resolve/main/mixtral-critics-malaysia-multiturn.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/mixtral-malaysian-general-qa/resolve/main/mixtral-critics-politician-multiturn.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b752b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/chatgpt-malay-instructions/resolve/main/synthetic-oss_instruct-decontaminated.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a955e645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/mixtral-malaysian-general-qa/resolve/main/mixtral-factual-wrong-v2.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33182040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head -n 1 mixtral-factual-wrong-v2.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4938493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/Malaysian-SFT/resolve/main/data/force_tamil-00000-of-00001.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4d35f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/Malaysian-SFT/resolve/main/data/force_mandarin-00000-of-00001.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea8e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/Malaysian-SFT/resolve/main/data/force_jawi-00000-of-00001.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb03c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "\n",
    "digits = set(string.digits)\n",
    "rejected = ['\\'', '\"', 'http', '\\n', '[', ']', '/', '`']\n",
    "\n",
    "def contains_non_ascii(text):\n",
    "    return any(ord(char) > 127 for char in text)\n",
    "\n",
    "def reject_q(q):\n",
    "    if q is None:\n",
    "        return True\n",
    "    if any([c in q for c in rejected]):\n",
    "        return True\n",
    "    if contains_non_ascii(q):\n",
    "        return True\n",
    "    if len(set(q) & digits):\n",
    "        return True\n",
    "    if len(q) < 20:\n",
    "        return True\n",
    "    if len(q) > 200:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def reject_a(a):\n",
    "    if a is None:\n",
    "        return True\n",
    "    if '------' in a:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def contains_tamil(text):\n",
    "    tamil_pattern = re.compile(r'[\\u0B80-\\u0BFF]')\n",
    "    return bool(tamil_pattern.search(text))\n",
    "\n",
    "def contains_mandarin(text):\n",
    "    return any(\n",
    "        '\\u4E00' <= char <= '\\u9FFF' or\n",
    "        '\\u3400' <= char <= '\\u4DBF' or\n",
    "        '\\U00020000' <= char <= '\\U0002EBEF'\n",
    "        for char in text\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fcc57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(row):\n",
    "    if '<bot>:' in row['input'] and row['output'] is None:\n",
    "        inputs, outputs = [], []\n",
    "        splitted = row['input'].split('<bot>:')\n",
    "        for i in range(len(splitted) - 1):\n",
    "            if i == 0:\n",
    "                human = splitted[i].replace('<manusia>:', '')\n",
    "            else:\n",
    "                try:\n",
    "                    human = splitted[i].split('<manusia>:')[1]\n",
    "                except BaseException:\n",
    "                    continue\n",
    "            bot = splitted[i + 1].split('<manusia>:')[0]\n",
    "            inputs.append(human)\n",
    "            outputs.append(bot)\n",
    "    else:\n",
    "        inputs = [row['input']]\n",
    "        outputs = [row['output']]\n",
    "\n",
    "    chat = []\n",
    "    if row['prompt_input'] is not None and len(row['prompt_input']):\n",
    "        chat.append({'role': 'system', 'content': row['prompt_input'].strip()})\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        chat.extend([\n",
    "            {'role': 'user', 'content': input.strip()},\n",
    "            {'role': 'assistant', 'content': output.strip()},\n",
    "        ])\n",
    "    return chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac0ab8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29122"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('chatgpt4_malaysian_general_qa-00000-of-00001.parquet')\n",
    "\n",
    "filtered = []\n",
    "for i in range(len(df)):\n",
    "    q = df['input'].iloc[i]\n",
    "    \n",
    "    if reject_q(q):\n",
    "        continue\n",
    "    \n",
    "    filtered.append(('chatgpt4_malaysian_general_qa', df.iloc[i].to_dict()))\n",
    "    \n",
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bfcb124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 149054/149054 [00:17<00:00, 8461.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "105238"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('malaysian_ultrachat-00000-of-00001.parquet')\n",
    "\n",
    "filter_ultrachat = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    l = generate_and_tokenize_prompt(df.iloc[i].to_dict())\n",
    "    valid = True\n",
    "    for no, l_ in enumerate(l):\n",
    "        left = re.sub('[^a-z ]+', ' ', l_['content'][:20].lower())\n",
    "        left = re.sub(r'[ ]+', ' ', left).strip()\n",
    "        right = re.sub('[^a-z ]+', ' ', l[no - 1]['content'][:20].lower())\n",
    "        right = re.sub(r'[ ]+', ' ', right).strip()\n",
    "        if left[:10] == right[:10]:\n",
    "            valid = False\n",
    "            break\n",
    "    if not valid:\n",
    "        continue\n",
    "    l_ = json.dumps(l).lower()\n",
    "    if 'dalam konteks di' in l_:\n",
    "        continue\n",
    "    if 'terjemah' in l_:\n",
    "        continue\n",
    "    if 'artikel itu' in l_:\n",
    "        continue\n",
    "        \n",
    "    q = l[0]['content'].split('\\n')[-1]\n",
    "    if reject_q(q):\n",
    "        continue\n",
    "    \n",
    "    filter_ultrachat.append(('malaysian_ultrachat', l))\n",
    "    \n",
    "len(filter_ultrachat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f684572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51738it [00:01, 37013.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpaca = []\n",
    "with open('synthetic-alpaca_data_cleaned.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        if l['indon_output']:\n",
    "            continue\n",
    "        if l['rejected_output']:\n",
    "            continue\n",
    "        if l['output_ms'] is None:\n",
    "            continue\n",
    "        q = l['instruction']\n",
    "        \n",
    "        if reject_q(q):\n",
    "            continue\n",
    "            \n",
    "        if reject_a(l['output_ms']):\n",
    "            continue\n",
    "    \n",
    "        alpaca.append(('malaysian_alpaca', l))\n",
    "            \n",
    "len(alpaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "937a7c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111920it [00:03, 36717.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3550"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_code = []\n",
    "with open('synthetic-code-instructions.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        if l['indon_output']:\n",
    "            continue\n",
    "        if l['rejected_output']:\n",
    "            continue\n",
    "        if l['output_ms'] is None:\n",
    "            continue\n",
    "        if '```' not in l['output_ms']:\n",
    "            continue\n",
    "        q = l['instruction']\n",
    "        if reject_q(q):\n",
    "            continue\n",
    "\n",
    "        synthetic_code.append(('synthetic_coding', l))\n",
    "        \n",
    "len(synthetic_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25171560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103242it [00:08, 11873.85it/s]\n",
      "135770it [00:12, 10509.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "241115"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixtral_conversation = []\n",
    "already = set()\n",
    "\n",
    "global_break = False\n",
    "with open('mixtral-conversation-stupid.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        if global_break:\n",
    "            break\n",
    "        l = json.loads(l)\n",
    "        if len(l) % 2 != 0:\n",
    "            l = l[:-1]\n",
    "        for i in range(0, len(l), 2):\n",
    "            q = l[i]['content_ms']\n",
    "            a = l[i + 1]['content_ms']\n",
    "            if reject_q(q):\n",
    "                continue\n",
    "            if reject_a(a):\n",
    "                continue\n",
    "            if q in already:\n",
    "                continue\n",
    "            \n",
    "            mixtral_conversation.append(('mixtral_conversation_stupid', l[i: i + 2]))\n",
    "            already.add(q)\n",
    "            if len(mixtral_conversation) >= 50000:\n",
    "                global_break = True\n",
    "                break\n",
    "        \n",
    "global_break = False           \n",
    "with open('mixtral-critics-malaysia-multiturn.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        if global_break:\n",
    "            break\n",
    "        l = json.loads(l)\n",
    "        if len(l) % 2 != 0:\n",
    "            l = l[:-1]\n",
    "        for i in range(0, len(l), 2):\n",
    "            q = l[i]['content_ms']\n",
    "            a = l[i + 1]['content_ms']\n",
    "            if reject_q(q):\n",
    "                continue\n",
    "            if reject_a(a):\n",
    "                continue\n",
    "            if q in already:\n",
    "                continue\n",
    "            mixtral_conversation.append(('mixtral_critis_malaysia', l[i: i + 2]))\n",
    "            already.add(q)\n",
    "            if len(mixtral_conversation) >= 150000:\n",
    "                global_break = True\n",
    "                break\n",
    "                \n",
    "global_break = False           \n",
    "with open('mixtral-critics-politician-multiturn.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        if global_break:\n",
    "            break\n",
    "        l = json.loads(l)\n",
    "        if len(l) % 2 != 0:\n",
    "            l = l[:-1]\n",
    "        for i in range(0, len(l), 2):\n",
    "            q = l[i]['content_ms']\n",
    "            a = l[i + 1]['content_ms']\n",
    "            if reject_q(q):\n",
    "                continue\n",
    "            if reject_a(a):\n",
    "                continue\n",
    "            if q in already:\n",
    "                continue\n",
    "            mixtral_conversation.append(('mixtral_critis_politician', l[i: i + 2]))\n",
    "            already.add(q)\n",
    "            if len(mixtral_conversation) >= 250000:\n",
    "                global_break = True\n",
    "                break\n",
    "                \n",
    "len(mixtral_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbe726ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38937"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factual_wrong = []\n",
    "with open('mixtral-factual-wrong-v2.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        q = l['question_ms']\n",
    "        a = l['answer_ms']\n",
    "        if reject_q(q):\n",
    "            continue\n",
    "        if reject_a(a):\n",
    "            continue\n",
    "        factual_wrong.append(('mixtral_factually_wrong', l))\n",
    "        \n",
    "len(factual_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84687a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 52144/52144 [00:01<00:00, 40360.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('force_tamil-00000-of-00001.parquet')\n",
    "forces = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = generate_and_tokenize_prompt(df.iloc[i].to_dict())\n",
    "    q = row[0]['content']\n",
    "    if contains_tamil(q):\n",
    "        continue\n",
    "    if reject_q(q.replace('\\n', '')):\n",
    "        continue\n",
    "    if len(row) == 2 and len(row[-1]['content']) < 100:\n",
    "        continue\n",
    "    forces.append(('force_tamil', row))\n",
    "len(forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d3f4ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 146811/146811 [00:06<00:00, 24124.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('force_mandarin-00000-of-00001.parquet')\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = generate_and_tokenize_prompt(df.iloc[i].to_dict())\n",
    "    q = row[0]['content']\n",
    "    if contains_mandarin(q):\n",
    "        continue\n",
    "    if reject_q(q.replace('\\n', '')):\n",
    "        continue\n",
    "    if len(row) == 2 and len(row[-1]['content']) < 100:\n",
    "        continue\n",
    "    forces.append(('force_mandarin', row))\n",
    "len(forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "260ce27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 371885/371885 [00:20<00:00, 18217.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108270"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('force_jawi-00000-of-00001.parquet')\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = generate_and_tokenize_prompt(df.iloc[i].to_dict())\n",
    "    q = row[0]['content']\n",
    "    if contains_mandarin(q):\n",
    "        continue\n",
    "    if reject_q(q.replace('\\n', '')):\n",
    "        continue\n",
    "    if len(row) == 2 and len(row[-1]['content']) < 100:\n",
    "        continue\n",
    "    forces.append(('force_jawi', row))\n",
    "len(forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03d4b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = {}\n",
    "for f in filtered:\n",
    "    type, f = f\n",
    "    prompt = [\n",
    "        {'role': 'user', 'content': [\n",
    "            {\"type\": \"audio\", \"audio_url\": \"audio.wav\"},\n",
    "        ]},\n",
    "        {'role': 'assistant', 'content': f['output']},\n",
    "    ]\n",
    "    instructions[json.dumps(prompt)] = type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c2224db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in filter_ultrachat:\n",
    "    type, f = f\n",
    "    q = f[0]['content'].split('\\n')[-1]\n",
    "    prompt = [\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"audio\", \"audio_url\": \"audio.wav\"},\n",
    "            {\"type\": \"text\", \"text\": '\\n'.join(f[0]['content'].split('\\n')[:-1])},\n",
    "        ]}\n",
    "    ]\n",
    "    prompt.extend(f[1:])\n",
    "    instructions[json.dumps(prompt)] = type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcfc326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in alpaca:\n",
    "    type, f = f\n",
    "    prompt = [\n",
    "        {'role': 'user', 'content': [\n",
    "            {\"type\": \"audio\", \"audio_url\": \"audio.wav\"},\n",
    "        ]},\n",
    "        {'role': 'assistant', 'content': f['output_ms']},\n",
    "    ]\n",
    "    instructions[json.dumps(prompt)] = type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73242265",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in synthetic_code:\n",
    "    type, f = f\n",
    "    prompt = [\n",
    "        {'role': 'user', 'content': [\n",
    "            {\"type\": \"audio\", \"audio_url\": \"audio.wav\"},\n",
    "        ]},\n",
    "        {'role': 'assistant', 'content': f['output_ms']},\n",
    "    ]\n",
    "    instructions[json.dumps(prompt)] = type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f3b44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in mixtral_conversation:\n",
    "    type, f = f\n",
    "    accept = True\n",
    "    for f_ in f:\n",
    "        if f_['content_ms'] is None:\n",
    "            accept = False\n",
    "    if not accept:\n",
    "        continue\n",
    "        \n",
    "    prompt = [\n",
    "        {'role': 'user', 'content': [\n",
    "            {\"type\": \"audio\", \"audio_url\": \"audio.wav\"},\n",
    "        ]},\n",
    "        {'role': 'assistant', 'content': f[1]['content_ms']},\n",
    "    ]\n",
    "    \n",
    "    instructions[json.dumps(prompt)] = type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4b6f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in factual_wrong:\n",
    "    type, f = f\n",
    "    prompt = [\n",
    "        {'role': 'user', 'content': [\n",
    "            {\"type\": \"audio\", \"audio_url\": \"audio.wav\"},\n",
    "        ]},\n",
    "        {'role': 'assistant', 'content': f['answer_ms']},\n",
    "    ]\n",
    "    instructions[json.dumps(prompt)] = type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2939aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in forces:\n",
    "    type, f = f\n",
    "    q = f[0]['content'].replace('\\n\\n', ', ')\n",
    "    prompt = [\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"audio\", \"audio_url\": \"audio.wav\"},\n",
    "        ]}\n",
    "    ]\n",
    "    prompt.extend(f[1:])\n",
    "    instructions[json.dumps(prompt)] = type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7fbd176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539097"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06b85560",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('instructions-keys.json', 'w') as fopen:\n",
    "    json.dump(instructions, fopen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
